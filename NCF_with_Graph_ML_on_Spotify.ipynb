{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariel-hedvat/AdvancedMLDLCourseAssignments/blob/main/NCF_with_Graph_ML_on_Spotify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsB3rwoGeCUw"
      },
      "source": [
        "# **Neural Collaborative Filtering Using Graph Machine Learning**\n",
        "*Lukas Haas, Michal Skreta*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We implement LightGCN from scratch and apply it to the Spotify 1 Million Playlist Dataset to predict which songs belong to which playlist."
      ],
      "metadata": {
        "id": "ga6OkHQ5uZ6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installations**"
      ],
      "metadata": {
        "id": "6GXALiveuWHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets import all required packages first."
      ],
      "metadata": {
        "id": "jKcju8SPurXm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Te6mgyUReHBO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pXHYVeGHePlj",
        "outputId": "0953dd2e-ab91-4930-958c-7bc1249c23cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kmleNzaeD4u",
        "outputId": "1a453034-1c65-4363-a787-78b4fcd7adb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=504020 sha256=da812317e8b8383f946c6f375e930eb8c9b955a3ebac179513fe88064e99d631\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.25.2)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl size=1071448 sha256=f523c0d1c810443daa7d58130d799a8aacd07a1c2d4dcc4ff5397713d2734571\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.3.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install -U -q PyDrive\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAb4gubveET1",
        "outputId": "ae3b630c-73c5-4e6a-c20c-1d5395a4e846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1\n"
          ]
        }
      ],
      "source": [
        "import torch_geometric\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "print(torch_geometric.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V9JAM4Vpeg4m"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from deepsnap.hetero_graph import HeteroGraph\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deepsnap\n",
        "from deepsnap.graph import Graph\n",
        "from deepsnap.batch import Batch\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from deepsnap.hetero_gnn import forward_op\n",
        "from deepsnap.hetero_graph import HeteroGraph\n",
        "from sklearn.metrics import f1_score, roc_auc_score"
      ],
      "metadata": {
        "id": "oSkOpEDi7FJD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "VNrozvbUX_W1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path as Data_Path\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from itertools import combinations"
      ],
      "metadata": {
        "id": "pAuwKtffoqEK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "4LynIfv6peGw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XVZ9KPUetg_"
      },
      "source": [
        "## **Loading the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we can host the Spotify 1 Million Playlist Dataset ourselves due to copyright restrictions, head over to the offical challenge site to access and download the dataset.\n",
        "\n",
        "**Spotify 1 Million Playlist Dataset**: https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge/dataset_files\n",
        "\n",
        "**Important Note**:\n",
        "\n",
        "The dataset, unzipped, is about 33.5 gigabytes of JSON files each containing 1'000 playlists with the songs they contain. Since this tutorial does not require all data, we will only work with the fist 100k playlists (or 100 files) in the data folder of the unzipped file.\n",
        "\n",
        "Once you have downloaded the dataset, you have the following two options:\n",
        "\n",
        "**Option 1**:\n",
        "1. If your Google Colab environment has enough disk space and RAM, create an empty folder called \"data\" in the \"files\" section on Colab.\n",
        "2. Upload the first 100 .json playlist files (first 100k playlists) of the dataset to the \"data\" folder.\n",
        "3. Run the below \"Loading the Dataset\" code right here in Google Colab.\n",
        "\n",
        "**Option 2**:\n",
        "1. Download this Google Colab as a Juypter Notebook\n",
        "2. Run the \"Loading the Dataset\" code locally on your machine\n",
        "3. Name the resulting file \"plst_track_artist_graph.txt\"\n",
        "4. Upload the resulting file to \"files\"\n",
        "5. Proceed with the \"Preprocessing the Dataset\" section."
      ],
      "metadata": {
        "id": "aVeV-UHAUhmR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check if your dataset upload was successful:"
      ],
      "metadata": {
        "id": "4xVRSjvTV6vH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "HZgI9mh0UsbU",
        "outputId": "b3f80269-58fc-4e06-e180-e03a704e6ff5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAIN_DIR = \"drive/MyDrive/CS 224W Project_50\"\n",
        "DATA_PATH = Data_Path('spotify_million_playlist_dataset/data')\n",
        "os.chdir(MAIN_DIR)"
      ],
      "metadata": {
        "id": "fBWclrwEUzLa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA_PATH = Data_Path('data')"
      ],
      "metadata": {
        "id": "dI8NO0o1XYWM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not DATA_PATH.exists():\n",
        "    print(\"Oops, file doesn't exist!\")\n",
        "else:\n",
        "    print(\"Yay, the file exists!\")"
      ],
      "metadata": {
        "id": "CyBgaJOjUZhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ac2ef9-8ec7-492a-ef77-8f9ebee94b70"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yay, the file exists!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at a single example of a playlist."
      ],
      "metadata": {
        "id": "CJa3-ef9E4fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = [f for f in listdir(DATA_PATH) if isfile(join(DATA_PATH, f)) and '.json' in f]\n",
        "with open(join(DATA_PATH, file_names[0])) as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "example_plst = data['playlists'][0]\n",
        "example_plst"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47qFenp6E3jF",
        "outputId": "d514146f-98a4-4e07-fd23-eea5b03686e6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'NewNew',\n",
              " 'collaborative': 'false',\n",
              " 'pid': 7000,\n",
              " 'modified_at': 1509321600,\n",
              " 'num_tracks': 83,\n",
              " 'num_albums': 78,\n",
              " 'num_followers': 2,\n",
              " 'tracks': [{'pos': 0,\n",
              "   'artist_name': 'WILDES',\n",
              "   'track_uri': 'spotify:track:3uvsVUrAaGQJCTEUR1S3Sx',\n",
              "   'artist_uri': 'spotify:artist:0ypTT9UqAU5sZpPo5JZmjR',\n",
              "   'track_name': 'Bare',\n",
              "   'album_uri': 'spotify:album:2kIoMj5Ht14l2PnNRa2abC',\n",
              "   'duration_ms': 242060,\n",
              "   'album_name': 'Bare'},\n",
              "  {'pos': 1,\n",
              "   'artist_name': 'MIIA',\n",
              "   'track_uri': 'spotify:track:0heE5tAAaDQmnGhVDImPl2',\n",
              "   'artist_uri': 'spotify:artist:0h3YCmvRJ2jqt4jFiR6nGL',\n",
              "   'track_name': 'Dynasty',\n",
              "   'album_uri': 'spotify:album:3g7TTE6375PGIBsM9Tlk9I',\n",
              "   'duration_ms': 225515,\n",
              "   'album_name': 'Dynasty'},\n",
              "  {'pos': 2,\n",
              "   'artist_name': 'Cold War Kids',\n",
              "   'track_uri': 'spotify:track:3omXshBamrREltcf24gYDC',\n",
              "   'artist_uri': 'spotify:artist:6VDdCwrBM4qQaGxoAyxyJC',\n",
              "   'track_name': 'First',\n",
              "   'album_uri': 'spotify:album:2H09itV5a5yUcGyk9u9HwY',\n",
              "   'duration_ms': 200360,\n",
              "   'album_name': 'Hold My Home'},\n",
              "  {'pos': 3,\n",
              "   'artist_name': 'Violet Days',\n",
              "   'track_uri': 'spotify:track:6TYWE19e35N7Bn5heHwyY6',\n",
              "   'artist_uri': 'spotify:artist:4uNv6RD2YXwoaKgHfJZkkL',\n",
              "   'track_name': 'Your Girl',\n",
              "   'album_uri': 'spotify:album:38y7zXf95O9Afh7ZXIoyq1',\n",
              "   'duration_ms': 232642,\n",
              "   'album_name': 'Your Girl'},\n",
              "  {'pos': 4,\n",
              "   'artist_name': 'Drake',\n",
              "   'track_uri': 'spotify:track:1xznGGDReH1oQq0xzbwXa3',\n",
              "   'artist_uri': 'spotify:artist:3TVXtAsR1Inumwj472S9r4',\n",
              "   'track_name': 'One Dance',\n",
              "   'album_uri': 'spotify:album:3hARKC8cinq3mZLLAEaBh9',\n",
              "   'duration_ms': 173986,\n",
              "   'album_name': 'Views'},\n",
              "  {'pos': 5,\n",
              "   'artist_name': 'Charlotte Cardin',\n",
              "   'track_uri': 'spotify:track:0yy6a8NCTaaVQwyEPIi8UU',\n",
              "   'artist_uri': 'spotify:artist:1G0YV9WooUBjrwDq0Q7EFK',\n",
              "   'track_name': \"Like It Doesn't Hurt (feat. Husser)\",\n",
              "   'album_uri': 'spotify:album:03Mt9e0CBDHql28QNn4gbT',\n",
              "   'duration_ms': 217544,\n",
              "   'album_name': 'Main Girl'},\n",
              "  {'pos': 6,\n",
              "   'artist_name': 'Adele',\n",
              "   'track_uri': 'spotify:track:4vb4mFvYsr2h6enhjJsq9Y',\n",
              "   'artist_uri': 'spotify:artist:4dpARuHxo51G3z768sgnrY',\n",
              "   'track_name': 'Water Under the Bridge',\n",
              "   'album_uri': 'spotify:album:0K4pIOOsfJ9lK8OjrZfXzd',\n",
              "   'duration_ms': 240426,\n",
              "   'album_name': '25'},\n",
              "  {'pos': 7,\n",
              "   'artist_name': 'Garrett Kato',\n",
              "   'track_uri': 'spotify:track:4DMg5fvBfDLannugAGN2QG',\n",
              "   'artist_uri': 'spotify:artist:4S3VOqqGguEZu3vbJMig4t',\n",
              "   'track_name': 'Sweet Jane',\n",
              "   'album_uri': 'spotify:album:0Bc6vNUNCliO2yIDtpGNL6',\n",
              "   'duration_ms': 200433,\n",
              "   'album_name': 'That Low and Lonesome Sound'},\n",
              "  {'pos': 8,\n",
              "   'artist_name': 'Of Monsters and Men',\n",
              "   'track_uri': 'spotify:track:1Jx5IdnXAJCKZ8EuczL5gX',\n",
              "   'artist_uri': 'spotify:artist:4dwdTW1Lfiq0cM8nBAqIIz',\n",
              "   'track_name': 'Black Water',\n",
              "   'album_uri': 'spotify:album:4PAyBqzCYoIIjjPFszeqgT',\n",
              "   'duration_ms': 253293,\n",
              "   'album_name': 'Beneath The Skin'},\n",
              "  {'pos': 9,\n",
              "   'artist_name': 'Broods',\n",
              "   'track_uri': 'spotify:track:6NYtqWYqMbnzoEU9jXla80',\n",
              "   'artist_uri': 'spotify:artist:5r5Va4lVQ1zjEfbJSrmCsS',\n",
              "   'track_name': 'Taking You There',\n",
              "   'album_uri': 'spotify:album:17vQyc1dhEyxV6q5AxOWh8',\n",
              "   'duration_ms': 189080,\n",
              "   'album_name': 'Broods'},\n",
              "  {'pos': 10,\n",
              "   'artist_name': 'Beauville',\n",
              "   'track_uri': 'spotify:track:1WoJEWUPjhCTwfbOeUjoCI',\n",
              "   'artist_uri': 'spotify:artist:4uf9PIXkZQTXqzl5gyDJLj',\n",
              "   'track_name': 'Letting In',\n",
              "   'album_uri': 'spotify:album:2wJq45aYneDKVLejGJmTGl',\n",
              "   'duration_ms': 263466,\n",
              "   'album_name': 'Letting In'},\n",
              "  {'pos': 11,\n",
              "   'artist_name': 'P!nk',\n",
              "   'track_uri': 'spotify:track:432fRHq6vKAP11oUDYDPiY',\n",
              "   'artist_uri': 'spotify:artist:1KCSPY1glIKqW2TotWuXOR',\n",
              "   'track_name': 'Sober',\n",
              "   'album_uri': 'spotify:album:2MqP4akeOQpLkq7jpQqlHT',\n",
              "   'duration_ms': 251533,\n",
              "   'album_name': 'Funhouse: The Tour Edition'},\n",
              "  {'pos': 12,\n",
              "   'artist_name': 'P!nk',\n",
              "   'track_uri': 'spotify:track:1DasuoqKuAymXhEpgSqrlx',\n",
              "   'artist_uri': 'spotify:artist:1KCSPY1glIKqW2TotWuXOR',\n",
              "   'track_name': 'U + Ur Hand',\n",
              "   'album_uri': 'spotify:album:0RBX3mBilzQMI0VLpfcmo1',\n",
              "   'duration_ms': 214386,\n",
              "   'album_name': \"I'm Not Dead\"},\n",
              "  {'pos': 13,\n",
              "   'artist_name': 'P!nk',\n",
              "   'track_uri': 'spotify:track:2ZQ4Q9xL7W8FEgO1d4o7YH',\n",
              "   'artist_uri': 'spotify:artist:1KCSPY1glIKqW2TotWuXOR',\n",
              "   'track_name': \"Don't Let Me Get Me - LP Version/Radio Edit\",\n",
              "   'album_uri': 'spotify:album:03pT16iWbhVKpDodI37D8b',\n",
              "   'duration_ms': 210626,\n",
              "   'album_name': 'M!ssundaztood'},\n",
              "  {'pos': 14,\n",
              "   'artist_name': 'Grace',\n",
              "   'track_uri': 'spotify:track:6KI1ZpZWYAJLvmVhCJz65G',\n",
              "   'artist_uri': 'spotify:artist:6y5amJcTjeDgLXIjtQLMst',\n",
              "   'track_name': \"You Don't Own Me\",\n",
              "   'album_uri': 'spotify:album:2AUhyBQANk5FKHD6WCbxja',\n",
              "   'duration_ms': 201493,\n",
              "   'album_name': 'FMA'},\n",
              "  {'pos': 15,\n",
              "   'artist_name': 'Miranda Lambert',\n",
              "   'track_uri': 'spotify:track:4Qtw0HNKSbIRT5sWUnbRXc',\n",
              "   'artist_uri': 'spotify:artist:66lH4jAE7pqPlOlzUKbwA0',\n",
              "   'track_name': 'Vice',\n",
              "   'album_uri': 'spotify:album:563h536tB6n8Dn62jr4RZG',\n",
              "   'duration_ms': 240280,\n",
              "   'album_name': 'The Weight of These Wings'},\n",
              "  {'pos': 16,\n",
              "   'artist_name': 'Alicia Keys',\n",
              "   'track_uri': 'spotify:track:0JEqGkvUiMTQmFY6sgL9kg',\n",
              "   'artist_uri': 'spotify:artist:3DiDSECUqqY1AuBP8qtaIa',\n",
              "   'track_name': 'No One',\n",
              "   'album_uri': 'spotify:album:0neqylYFL6s6Ikdf3UFmUo',\n",
              "   'duration_ms': 253813,\n",
              "   'album_name': 'As I Am'},\n",
              "  {'pos': 17,\n",
              "   'artist_name': 'Beyoncé',\n",
              "   'track_uri': 'spotify:track:7zP67rufQgoODWFI45jntD',\n",
              "   'artist_uri': 'spotify:artist:6vWDO969PvNqNYHIOW5v0m',\n",
              "   'track_name': 'Broken-Hearted Girl',\n",
              "   'album_uri': 'spotify:album:3ROfBX6lJLnCmaw1NrP5K9',\n",
              "   'duration_ms': 278400,\n",
              "   'album_name': 'I AM...SASHA FIERCE - Platinum Edition'},\n",
              "  {'pos': 18,\n",
              "   'artist_name': 'Beyoncé',\n",
              "   'track_uri': 'spotify:track:2wNGoon7FlKnVEyYS1ZRBQ',\n",
              "   'artist_uri': 'spotify:artist:6vWDO969PvNqNYHIOW5v0m',\n",
              "   'track_name': 'Sweet Dreams',\n",
              "   'album_uri': 'spotify:album:3ROfBX6lJLnCmaw1NrP5K9',\n",
              "   'duration_ms': 207480,\n",
              "   'album_name': 'I AM...SASHA FIERCE - Platinum Edition'},\n",
              "  {'pos': 19,\n",
              "   'artist_name': 'Beyoncé',\n",
              "   'track_uri': 'spotify:track:1leG3qAx1fYT1R4CXxxSm4',\n",
              "   'artist_uri': 'spotify:artist:6vWDO969PvNqNYHIOW5v0m',\n",
              "   'track_name': 'Scared of Lonely',\n",
              "   'album_uri': 'spotify:album:3ROfBX6lJLnCmaw1NrP5K9',\n",
              "   'duration_ms': 223586,\n",
              "   'album_name': 'I AM...SASHA FIERCE - Platinum Edition'},\n",
              "  {'pos': 20,\n",
              "   'artist_name': 'G-Eazy',\n",
              "   'track_uri': 'spotify:track:5sv4LTz8qayQYnXlzaxg2x',\n",
              "   'artist_uri': 'spotify:artist:02kJSzxNuaWGqwubyUba0Z',\n",
              "   'track_name': 'Drifting',\n",
              "   'album_uri': 'spotify:album:09Q3WwGYsQe5ognkvVkmCu',\n",
              "   'duration_ms': 273253,\n",
              "   'album_name': \"When It's Dark Out\"},\n",
              "  {'pos': 21,\n",
              "   'artist_name': 'Kevin Garrett',\n",
              "   'track_uri': 'spotify:track:41KAWBH3Tzn2R2VsVIJQnO',\n",
              "   'artist_uri': 'spotify:artist:56tbeL5xhBPxby544GuK3E',\n",
              "   'track_name': 'Precious',\n",
              "   'album_uri': 'spotify:album:1h1j5sn6ndCdweeHz8QlaA',\n",
              "   'duration_ms': 267973,\n",
              "   'album_name': 'Precious'},\n",
              "  {'pos': 22,\n",
              "   'artist_name': 'Drake',\n",
              "   'track_uri': 'spotify:track:4cRBqWBjuccCowYVHFlXK6',\n",
              "   'artist_uri': 'spotify:artist:3TVXtAsR1Inumwj472S9r4',\n",
              "   'track_name': 'Redemption',\n",
              "   'album_uri': 'spotify:album:40GMAhriYJRO1rsY4YdrZb',\n",
              "   'duration_ms': 333946,\n",
              "   'album_name': 'Views'},\n",
              "  {'pos': 23,\n",
              "   'artist_name': 'Dan Henig',\n",
              "   'track_uri': 'spotify:track:1wLT83ttda02hu1UKlAx8F',\n",
              "   'artist_uri': 'spotify:artist:0XZFE8OLIWVaJ6Kns5DmbH',\n",
              "   'track_name': 'Crash & Burn',\n",
              "   'album_uri': 'spotify:album:6Jyz3xZILT55CH732aMCtA',\n",
              "   'duration_ms': 227250,\n",
              "   'album_name': 'Paper Planes & Hurricanes'},\n",
              "  {'pos': 24,\n",
              "   'artist_name': 'Crowder',\n",
              "   'track_uri': 'spotify:track:6FIKWCqauK8J4g85iTVpuJ',\n",
              "   'artist_uri': 'spotify:artist:39xmI59WrIMyyJjSDq6WCu',\n",
              "   'track_name': 'Back To The Garden',\n",
              "   'album_uri': 'spotify:album:5UnaAIuMRqSBeBWY3XM0FQ',\n",
              "   'duration_ms': 255520,\n",
              "   'album_name': 'American Prodigal'},\n",
              "  {'pos': 25,\n",
              "   'artist_name': 'Thomas Lundell',\n",
              "   'track_uri': 'spotify:track:7cbtasOpzElEsBHo3lwhOT',\n",
              "   'artist_uri': 'spotify:artist:5mfZhLczjYLDRjGDjfenye',\n",
              "   'track_name': 'Slow Dance',\n",
              "   'album_uri': 'spotify:album:61XqrcfrC60X2wAeMPcsGQ',\n",
              "   'duration_ms': 199373,\n",
              "   'album_name': 'Slow Dance'},\n",
              "  {'pos': 26,\n",
              "   'artist_name': 'The Cains',\n",
              "   'track_uri': 'spotify:track:3yibJox9DBvo8dRfTz9zJs',\n",
              "   'artist_uri': 'spotify:artist:33DzUXjWGCvmzlXCpVliT0',\n",
              "   'track_name': 'Knock Knock',\n",
              "   'album_uri': 'spotify:album:6bxa12jsc767AeMi90DQl0',\n",
              "   'duration_ms': 204733,\n",
              "   'album_name': 'Knock Knock'},\n",
              "  {'pos': 27,\n",
              "   'artist_name': 'Holley Maher',\n",
              "   'track_uri': 'spotify:track:0x2kJ54nT96frJQ27700jS',\n",
              "   'artist_uri': 'spotify:artist:3GDAPdQP9OYzIlhd7HkbJj',\n",
              "   'track_name': 'I Do',\n",
              "   'album_uri': 'spotify:album:1WPoh6fbUUAapxP6xfeY9D',\n",
              "   'duration_ms': 219675,\n",
              "   'album_name': 'Euphorics'},\n",
              "  {'pos': 28,\n",
              "   'artist_name': 'Maren Morris',\n",
              "   'track_uri': 'spotify:track:58spuRyMUsjKHQHEGwLC99',\n",
              "   'artist_uri': 'spotify:artist:6WY7D3jk8zTrHtmkqqo5GI',\n",
              "   'track_name': '80s Mercedes',\n",
              "   'album_uri': 'spotify:album:4sSXylKcBB3p47VfrBJlfK',\n",
              "   'duration_ms': 211767,\n",
              "   'album_name': 'HERO (Deluxe Edition)'},\n",
              "  {'pos': 29,\n",
              "   'artist_name': 'Ellie Lawrence',\n",
              "   'track_uri': 'spotify:track:7m7oed7n2skIDQrXd1jWWK',\n",
              "   'artist_uri': 'spotify:artist:4WEktD91o6r6F9IpCuPOf9',\n",
              "   'track_name': 'We Don’t Have To Take Our Clothes Off - The Voice Performance',\n",
              "   'album_uri': 'spotify:album:13JKH8Kzk1AqMw9zB6oZ6E',\n",
              "   'duration_ms': 194613,\n",
              "   'album_name': 'We Don’t Have To Take Our Clothes Off'},\n",
              "  {'pos': 30,\n",
              "   'artist_name': 'Who Is Fancy',\n",
              "   'track_uri': 'spotify:track:6K5xY7EabiBLjd2HuBQIak',\n",
              "   'artist_uri': 'spotify:artist:5QSx2vpiSchSeCwc0qmfNI',\n",
              "   'track_name': 'Goodbye',\n",
              "   'album_uri': 'spotify:album:3wXSqg2UGr5JOlCcxWR7K4',\n",
              "   'duration_ms': 206213,\n",
              "   'album_name': 'Goodbye'},\n",
              "  {'pos': 31,\n",
              "   'artist_name': 'Emeli Sandé',\n",
              "   'track_uri': 'spotify:track:703KxRua8b81baRowcnzRP',\n",
              "   'artist_uri': 'spotify:artist:7sfgqEdoeBTjd8lQsPT3Cy',\n",
              "   'track_name': 'Next To Me',\n",
              "   'album_uri': 'spotify:album:2hY1mb0x56O1zxB4w1bqp4',\n",
              "   'duration_ms': 197106,\n",
              "   'album_name': 'Our Version Of Events'},\n",
              "  {'pos': 32,\n",
              "   'artist_name': 'Sam Feldt',\n",
              "   'track_uri': 'spotify:track:6ksRossV4vKsXntCCZbhaM',\n",
              "   'artist_uri': 'spotify:artist:20gsENnposVs2I4rQ5kvrf',\n",
              "   'track_name': 'Show Me Love',\n",
              "   'album_uri': 'spotify:album:1Ba3HDw1at35UVxMxLCdCa',\n",
              "   'duration_ms': 181867,\n",
              "   'album_name': 'Show Me Love'},\n",
              "  {'pos': 33,\n",
              "   'artist_name': 'James TW',\n",
              "   'track_uri': 'spotify:track:7lwYNEUrDP4thCD6nQ4nBv',\n",
              "   'artist_uri': 'spotify:artist:0B3N0ZINFWvizfa8bKiz4v',\n",
              "   'track_name': 'Torn - Bonus Track',\n",
              "   'album_uri': 'spotify:album:6ZPn3tnyLZAbgLFy3GSkqT',\n",
              "   'duration_ms': 196213,\n",
              "   'album_name': 'First Impressions'},\n",
              "  {'pos': 34,\n",
              "   'artist_name': 'Alessia Cara',\n",
              "   'track_uri': 'spotify:track:0prNGof3XqfTvNDxHonvdK',\n",
              "   'artist_uri': 'spotify:artist:2wUjUUtkb5lvLKcGKsKqsR',\n",
              "   'track_name': 'Scars To Your Beautiful',\n",
              "   'album_uri': 'spotify:album:3rDbA12I5duZnlwakqDdZa',\n",
              "   'duration_ms': 230226,\n",
              "   'album_name': 'Know-It-All'},\n",
              "  {'pos': 35,\n",
              "   'artist_name': 'X Ambassadors',\n",
              "   'track_uri': 'spotify:track:52gOkogiDc13DWi5zX0PKD',\n",
              "   'artist_uri': 'spotify:artist:3NPpFNZtSTHheNBaWC82rB',\n",
              "   'track_name': 'American Oxygen',\n",
              "   'album_uri': 'spotify:album:16Hlh4TrIkVgbGEKqioCPO',\n",
              "   'duration_ms': 305093,\n",
              "   'album_name': 'American Oxygen'},\n",
              "  {'pos': 36,\n",
              "   'artist_name': 'Jon Bellion',\n",
              "   'track_uri': 'spotify:track:1CnPYaKxTVb4LWOtiGOm0m',\n",
              "   'artist_uri': 'spotify:artist:50JJSqHUf2RQ9xsHs0KMHg',\n",
              "   'track_name': 'All Time Low',\n",
              "   'album_uri': 'spotify:album:2e8nzTZ0HtK94IifOWgN7o',\n",
              "   'duration_ms': 217603,\n",
              "   'album_name': 'The Human Condition'},\n",
              "  {'pos': 37,\n",
              "   'artist_name': 'Javier Colon',\n",
              "   'track_uri': 'spotify:track:0tnQuuvgFnJhC7fnwiLo3B',\n",
              "   'artist_uri': 'spotify:artist:3flTDj1VSZCktpBGZlNutt',\n",
              "   'track_name': 'Gravity',\n",
              "   'album_uri': 'spotify:album:7jCuPGpiiBPDRrxFPq0HJh',\n",
              "   'duration_ms': 234080,\n",
              "   'album_name': 'Gravity'},\n",
              "  {'pos': 38,\n",
              "   'artist_name': 'Hillsong Young & Free',\n",
              "   'track_uri': 'spotify:track:3QntQwzIBV704yqCHLLmyH',\n",
              "   'artist_uri': 'spotify:artist:7m4gF38CPATtHrk5HS42WZ',\n",
              "   'track_name': 'Sinking Deep',\n",
              "   'album_uri': 'spotify:album:7h7W5MDYWmSYGSAag53umc',\n",
              "   'duration_ms': 247373,\n",
              "   'album_name': 'This Is Living'},\n",
              "  {'pos': 39,\n",
              "   'artist_name': 'Hillsong Young & Free',\n",
              "   'track_uri': 'spotify:track:3QntQwzIBV704yqCHLLmyH',\n",
              "   'artist_uri': 'spotify:artist:7m4gF38CPATtHrk5HS42WZ',\n",
              "   'track_name': 'Sinking Deep',\n",
              "   'album_uri': 'spotify:album:7h7W5MDYWmSYGSAag53umc',\n",
              "   'duration_ms': 247373,\n",
              "   'album_name': 'This Is Living'},\n",
              "  {'pos': 40,\n",
              "   'artist_name': 'Zara Larsson',\n",
              "   'track_uri': 'spotify:track:4Q4jmPHwu0wrJvqrld0FQ6',\n",
              "   'artist_uri': 'spotify:artist:1Xylc3o4UrD53lo9CvFvVg',\n",
              "   'track_name': 'I Would Like',\n",
              "   'album_uri': 'spotify:album:5YLRVHDVRw3QqWbeTGpC5B',\n",
              "   'duration_ms': 226720,\n",
              "   'album_name': 'So Good'},\n",
              "  {'pos': 41,\n",
              "   'artist_name': '3LAU',\n",
              "   'track_uri': 'spotify:track:0tkm2r0AXL6yVLR2jJMT9t',\n",
              "   'artist_uri': 'spotify:artist:4YLQaW1UU3mrVetC8gNkg5',\n",
              "   'track_name': 'You Want More',\n",
              "   'album_uri': 'spotify:album:1IOJTPTrGkonPg3RTue9ic',\n",
              "   'duration_ms': 180000,\n",
              "   'album_name': 'You Want More'},\n",
              "  {'pos': 42,\n",
              "   'artist_name': 'Little Big Town',\n",
              "   'track_uri': 'spotify:track:23TxRN09aR1RB0G0tFoT0b',\n",
              "   'artist_uri': 'spotify:artist:3CygdxquGHurS7f9LjNLkv',\n",
              "   'track_name': 'Better Man',\n",
              "   'album_uri': 'spotify:album:2aQOzEjLzPkffXDwREXdAh',\n",
              "   'duration_ms': 263120,\n",
              "   'album_name': 'The Breaker'},\n",
              "  {'pos': 43,\n",
              "   'artist_name': 'Little Big Town',\n",
              "   'track_uri': 'spotify:track:23TxRN09aR1RB0G0tFoT0b',\n",
              "   'artist_uri': 'spotify:artist:3CygdxquGHurS7f9LjNLkv',\n",
              "   'track_name': 'Better Man',\n",
              "   'album_uri': 'spotify:album:2aQOzEjLzPkffXDwREXdAh',\n",
              "   'duration_ms': 263120,\n",
              "   'album_name': 'The Breaker'},\n",
              "  {'pos': 44,\n",
              "   'artist_name': 'Matt Woods',\n",
              "   'track_uri': 'spotify:track:3eHumvv1LTzCwtFUJKF09v',\n",
              "   'artist_uri': 'spotify:artist:7lWm7B37N2Phj7l1bpEx91',\n",
              "   'track_name': 'In the Dark',\n",
              "   'album_uri': 'spotify:album:0TjnH7hM1wwG6e2WIgvxh5',\n",
              "   'duration_ms': 222352,\n",
              "   'album_name': 'In the Dark'},\n",
              "  {'pos': 45,\n",
              "   'artist_name': 'Kygo',\n",
              "   'track_uri': 'spotify:track:6HsbMH5Bgkp4QgAp7MVZ8z',\n",
              "   'artist_uri': 'spotify:artist:23fqKkggKUBHNkbKtXEls4',\n",
              "   'track_name': \"For What It's Worth\",\n",
              "   'album_uri': 'spotify:album:0uMIzWh1uEpHEBell4rlF8',\n",
              "   'duration_ms': 183106,\n",
              "   'album_name': 'Cloud Nine'},\n",
              "  {'pos': 46,\n",
              "   'artist_name': 'Post Malone',\n",
              "   'track_uri': 'spotify:track:75ZvA4QfFiZvzhj2xkaWAh',\n",
              "   'artist_uri': 'spotify:artist:246dkjvS1zLTtiykXe5h60',\n",
              "   'track_name': 'I Fall Apart',\n",
              "   'album_uri': 'spotify:album:5s0rmjP8XOPhP6HhqOhuyC',\n",
              "   'duration_ms': 223346,\n",
              "   'album_name': 'Stoney'},\n",
              "  {'pos': 47,\n",
              "   'artist_name': 'Luke Christopher',\n",
              "   'track_uri': 'spotify:track:3LFhPZqd9GC9sV8ZTnu99P',\n",
              "   'artist_uri': 'spotify:artist:787bCXOIvGeBw0Bc4kEjhD',\n",
              "   'track_name': 'Bedroom Trip',\n",
              "   'album_uri': 'spotify:album:2IMj47eMK6wKMG92meFN70',\n",
              "   'duration_ms': 200840,\n",
              "   'album_name': 'YSTRDY'},\n",
              "  {'pos': 48,\n",
              "   'artist_name': 'The Killers',\n",
              "   'track_uri': 'spotify:track:4qBCD7TslV1KdiFpT9cbnm',\n",
              "   'artist_uri': 'spotify:artist:0C0XlULifJtAgn6ZNCW2eu',\n",
              "   'track_name': 'Miss Atomic Bomb',\n",
              "   'album_uri': 'spotify:album:7cuwIlQNnnwVlfosv2Zm6U',\n",
              "   'duration_ms': 293506,\n",
              "   'album_name': 'Battle Born'},\n",
              "  {'pos': 49,\n",
              "   'artist_name': 'Gavin James',\n",
              "   'track_uri': 'spotify:track:0L9lXMXddmoBbBUeF7A9An',\n",
              "   'artist_uri': 'spotify:artist:25tMQOrIU4LlUo6Sv8v5SE',\n",
              "   'track_name': 'Nervous (The Ooh Song) - Mark McCabe Remix',\n",
              "   'album_uri': 'spotify:album:6jfuBG9u0Au2nWXGXTXmux',\n",
              "   'duration_ms': 195194,\n",
              "   'album_name': 'Nervous (The Ooh Song)'},\n",
              "  {'pos': 50,\n",
              "   'artist_name': 'Patrick Britt',\n",
              "   'track_uri': 'spotify:track:256h43UXaCLobHEcHlzJLa',\n",
              "   'artist_uri': 'spotify:artist:2RhZPV1RoSxUAkVBNmnwfZ',\n",
              "   'track_name': 'Slow Dance (Acoustic)',\n",
              "   'album_uri': 'spotify:album:5i0lI90QebNtOBmk7jrANI',\n",
              "   'duration_ms': 221750,\n",
              "   'album_name': 'Slow Dance (Acoustic)'},\n",
              "  {'pos': 51,\n",
              "   'artist_name': 'NEEDTOBREATHE',\n",
              "   'track_uri': 'spotify:track:1udBxtZiU03LC2hj8Uxdx3',\n",
              "   'artist_uri': 'spotify:artist:610EjgFatGvVPtib97jQ8G',\n",
              "   'track_name': \"Don't Leave Just Yet\",\n",
              "   'album_uri': 'spotify:album:1bgaogmQCdYuPrMs5H1XM4',\n",
              "   'duration_ms': 233426,\n",
              "   'album_name': 'Daylight'},\n",
              "  {'pos': 52,\n",
              "   'artist_name': 'Snakehips',\n",
              "   'track_uri': 'spotify:track:0Zx8khUcEfCFK2AEoIhC92',\n",
              "   'artist_uri': 'spotify:artist:2FwJwEswyIUAljqgjNSHgP',\n",
              "   'track_name': \"Don't Leave\",\n",
              "   'album_uri': 'spotify:album:6buSUFSCXUIj3DOH3gUoRe',\n",
              "   'duration_ms': 214693,\n",
              "   'album_name': \"Don't Leave\"},\n",
              "  {'pos': 53,\n",
              "   'artist_name': 'John Legend',\n",
              "   'track_uri': 'spotify:track:6nxQdXa1uAL0rY72wPZu89',\n",
              "   'artist_uri': 'spotify:artist:5y2Xq6xcjJb2jVM54GHK3t',\n",
              "   'track_name': 'Love Me Now',\n",
              "   'album_uri': 'spotify:album:7xMjYDrgPLp1ReFGAOyS1O',\n",
              "   'duration_ms': 210293,\n",
              "   'album_name': 'DARKNESS AND LIGHT'},\n",
              "  {'pos': 54,\n",
              "   'artist_name': 'The Killers',\n",
              "   'track_uri': 'spotify:track:6suRRwX61xSMfU7wJuCVdy',\n",
              "   'artist_uri': 'spotify:artist:0C0XlULifJtAgn6ZNCW2eu',\n",
              "   'track_name': 'For Reasons Unknown',\n",
              "   'album_uri': 'spotify:album:4o3RJndRhHxkieQzQGhmbw',\n",
              "   'duration_ms': 212266,\n",
              "   'album_name': \"Sam's Town\"},\n",
              "  {'pos': 55,\n",
              "   'artist_name': 'A R I Z O N A',\n",
              "   'track_uri': 'spotify:track:78mNkiUBAwHqjT0QOeEqqg',\n",
              "   'artist_uri': 'spotify:artist:7hOGhpa8RMSuDOWntGIAJt',\n",
              "   'track_name': 'Oceans Away - Sam Feldt Remix',\n",
              "   'album_uri': 'spotify:album:7wXmzWmxTBlH14JjbvdNfS',\n",
              "   'duration_ms': 171108,\n",
              "   'album_name': 'Oceans Away'},\n",
              "  {'pos': 56,\n",
              "   'artist_name': 'MAX',\n",
              "   'track_uri': 'spotify:track:1sYSP7gKa5kdKIfhANfori',\n",
              "   'artist_uri': 'spotify:artist:1bqxdqvUtPWZri43cKHac8',\n",
              "   'track_name': 'Lights Down Low',\n",
              "   'album_uri': 'spotify:album:2qmysBdftCYXRjYHTVK3qo',\n",
              "   'duration_ms': 223846,\n",
              "   'album_name': \"Hell's Kitchen Angel\"},\n",
              "  {'pos': 57,\n",
              "   'artist_name': 'Shawn Mendes',\n",
              "   'track_uri': 'spotify:track:36xPhTrbLeOegztjGwOgcW',\n",
              "   'artist_uri': 'spotify:artist:7n2wHs1TKAczGzO7Dd2rGr',\n",
              "   'track_name': 'Ruin',\n",
              "   'album_uri': 'spotify:album:6FLZDJq4UuwqcaQlI4XCP1',\n",
              "   'duration_ms': 241880,\n",
              "   'album_name': 'Illuminate'},\n",
              "  {'pos': 58,\n",
              "   'artist_name': 'Dierks Bentley',\n",
              "   'track_uri': 'spotify:track:2lFtnEmkIPm2ClN55e2chV',\n",
              "   'artist_uri': 'spotify:artist:7x8nK0m0cP2ksQf0mjWdPS',\n",
              "   'track_name': 'Black',\n",
              "   'album_uri': 'spotify:album:2GIrLP0PWskhZAJaHQtDux',\n",
              "   'duration_ms': 211160,\n",
              "   'album_name': 'Black'},\n",
              "  {'pos': 59,\n",
              "   'artist_name': 'Alanis Morissette',\n",
              "   'track_uri': 'spotify:track:2lE7oRoKssULAtbWViL385',\n",
              "   'artist_uri': 'spotify:artist:6ogn9necmbUdCppmNnGOdi',\n",
              "   'track_name': 'Hand In My Pocket - 2015 Remastered',\n",
              "   'album_uri': 'spotify:album:5Ap3F8CxjjsQKZGASDcHNA',\n",
              "   'duration_ms': 222013,\n",
              "   'album_name': 'Jagged Little Pill (Remastered)'},\n",
              "  {'pos': 60,\n",
              "   'artist_name': 'Alyssa Micaela',\n",
              "   'track_uri': 'spotify:track:3yWfHhUJvI1gsNqLXDrkDO',\n",
              "   'artist_uri': 'spotify:artist:7k7mCkZfVpQUXTgSowcpej',\n",
              "   'track_name': 'Clean Break',\n",
              "   'album_uri': 'spotify:album:5Neng2A2UhN0VCffFD8UtG',\n",
              "   'duration_ms': 214801,\n",
              "   'album_name': 'Cowboys Like That'},\n",
              "  {'pos': 61,\n",
              "   'artist_name': 'AJR',\n",
              "   'track_uri': 'spotify:track:3E2Zh20GDCR9B1EYjfXWyv',\n",
              "   'artist_uri': 'spotify:artist:6s22t5Y3prQHyaHWUN1R1C',\n",
              "   'track_name': 'Weak',\n",
              "   'album_uri': 'spotify:album:7LACXphpLTluKLFqHIZ1Qq',\n",
              "   'duration_ms': 201160,\n",
              "   'album_name': 'The Click'},\n",
              "  {'pos': 62,\n",
              "   'artist_name': 'Khalid',\n",
              "   'track_uri': 'spotify:track:248OFOZef6ShXv6DGgbnxU',\n",
              "   'artist_uri': 'spotify:artist:6LuN9FCkKOj5PcnpouEgny',\n",
              "   'track_name': 'Saved',\n",
              "   'album_uri': 'spotify:album:6kf46HbnYCZzP6rjvQHYzg',\n",
              "   'duration_ms': 206533,\n",
              "   'album_name': 'American Teen'},\n",
              "  {'pos': 63,\n",
              "   'artist_name': 'Shawn Mendes',\n",
              "   'track_uri': 'spotify:track:4qIx3QCBhshJ0aRr0GGRqx',\n",
              "   'artist_uri': 'spotify:artist:7n2wHs1TKAczGzO7Dd2rGr',\n",
              "   'track_name': 'No Promises',\n",
              "   'album_uri': 'spotify:album:6FLZDJq4UuwqcaQlI4XCP1',\n",
              "   'duration_ms': 166040,\n",
              "   'album_name': 'Illuminate'},\n",
              "  {'pos': 64,\n",
              "   'artist_name': 'Hey Violet',\n",
              "   'track_uri': 'spotify:track:0Xm8tw6qikotb8FAOZ2ks7',\n",
              "   'artist_uri': 'spotify:artist:4JNfz6aO9ZFz0gp5GY88am',\n",
              "   'track_name': 'Guys My Age',\n",
              "   'album_uri': 'spotify:album:6ZZbMKUghvClcRLF5pZT6Y',\n",
              "   'duration_ms': 213694,\n",
              "   'album_name': 'From The Outside'},\n",
              "  {'pos': 65,\n",
              "   'artist_name': 'Judah & the Lion',\n",
              "   'track_uri': 'spotify:track:2w7O4XCRoIJrwF1NqKL9TM',\n",
              "   'artist_uri': 'spotify:artist:3wWtfT7S2uVJJ3hGZlOLkZ',\n",
              "   'track_name': 'Take It All Back 2.0',\n",
              "   'album_uri': 'spotify:album:7vLmY8rLjLvOTQ0wk7Hqeh',\n",
              "   'duration_ms': 218355,\n",
              "   'album_name': \"Folk Hop N' Roll\"},\n",
              "  {'pos': 66,\n",
              "   'artist_name': 'Chance The Rapper',\n",
              "   'track_uri': 'spotify:track:6m9qPYXmhge2QhBLfFKnVF',\n",
              "   'artist_uri': 'spotify:artist:1anyVhU62p31KFi8MEzkbf',\n",
              "   'track_name': 'Same Drugs',\n",
              "   'album_uri': 'spotify:album:71QyofYesSsRMwFOTafnhB',\n",
              "   'duration_ms': 257775,\n",
              "   'album_name': 'Coloring Book'},\n",
              "  {'pos': 67,\n",
              "   'artist_name': 'Caroline Glaser',\n",
              "   'track_uri': 'spotify:track:5YFPG098MWESwbqT1D0cKq',\n",
              "   'artist_uri': 'spotify:artist:4qiAhwxeFLSbkNq6tFEWpJ',\n",
              "   'track_name': 'Your Love',\n",
              "   'album_uri': 'spotify:album:4zd3piahMJULe7zBWeZcxJ',\n",
              "   'duration_ms': 197018,\n",
              "   'album_name': 'Caroline Glaser'},\n",
              "  {'pos': 68,\n",
              "   'artist_name': 'Jillian Jacqueline',\n",
              "   'track_uri': 'spotify:track:5bPiULQ8j6EpEdEXisn7yi',\n",
              "   'artist_uri': 'spotify:artist:5GDZ6xhBwk7Yja97CFLmV7',\n",
              "   'track_name': 'Reasons',\n",
              "   'album_uri': 'spotify:album:1yUP241XpzjhNZK8WckQsv',\n",
              "   'duration_ms': 190226,\n",
              "   'album_name': 'Side A'},\n",
              "  {'pos': 69,\n",
              "   'artist_name': 'Keri Hilson',\n",
              "   'track_uri': 'spotify:track:1Ne9ZxBhUGwRVLHxzr7SnD',\n",
              "   'artist_uri': 'spotify:artist:63wjoROpeh5f11Qm93UiJ1',\n",
              "   'track_name': 'Energy - Main Final',\n",
              "   'album_uri': 'spotify:album:4ujRfwvBeflZJ7tzzA0XBJ',\n",
              "   'duration_ms': 209840,\n",
              "   'album_name': 'In A Perfect World...'},\n",
              "  {'pos': 70,\n",
              "   'artist_name': 'Rudimental',\n",
              "   'track_uri': 'spotify:track:6SUocL0caib4mLHe8ZrZzi',\n",
              "   'artist_uri': 'spotify:artist:4WN5naL3ofxrVBgFpguzKo',\n",
              "   'track_name': 'Sun Comes Up',\n",
              "   'album_uri': 'spotify:album:5UGyzp6HT8oy0eTkBfxtQ8',\n",
              "   'duration_ms': 232627,\n",
              "   'album_name': 'Sun Comes Up'},\n",
              "  {'pos': 71,\n",
              "   'artist_name': 'McKenna Breinholt',\n",
              "   'track_uri': 'spotify:track:0pxq04wmOwW0uMxnqoG21F',\n",
              "   'artist_uri': 'spotify:artist:2J5ZG3xD6VTCBOXnpn8r2B',\n",
              "   'track_name': 'I Wanted You',\n",
              "   'album_uri': 'spotify:album:4ok2RPucXW8h7pLfFFAzFC',\n",
              "   'duration_ms': 292066,\n",
              "   'album_name': 'I Wanted You'},\n",
              "  {'pos': 72,\n",
              "   'artist_name': 'Rita Ora',\n",
              "   'track_uri': 'spotify:track:4c2W3VKsOFoIg2SFaO6DY5',\n",
              "   'artist_uri': 'spotify:artist:5CCwRZC6euC8Odo6y9X8jr',\n",
              "   'track_name': 'Your Song',\n",
              "   'album_uri': 'spotify:album:6lrm01OVZZVmarH2XLSAXZ',\n",
              "   'duration_ms': 180757,\n",
              "   'album_name': 'Your Song'},\n",
              "  {'pos': 73,\n",
              "   'artist_name': 'Escort',\n",
              "   'track_uri': 'spotify:track:7gA0yghKRzS6bOwPKeg0Vw',\n",
              "   'artist_uri': 'spotify:artist:4zkiM9DSLNAOmoS5WtSQDt',\n",
              "   'track_name': 'Cocaine Blues',\n",
              "   'album_uri': 'spotify:album:08xCvkefUdrFFaqqff5W8S',\n",
              "   'duration_ms': 247706,\n",
              "   'album_name': 'Escort'},\n",
              "  {'pos': 74,\n",
              "   'artist_name': 'Nathaniel Rateliff & The Night Sweats',\n",
              "   'track_uri': 'spotify:track:1hWQvA6oGVJ2mAVsZ59AaV',\n",
              "   'artist_uri': 'spotify:artist:02seUFsFQP7TH4hLrTj77o',\n",
              "   'track_name': 'S.O.B.',\n",
              "   'album_uri': 'spotify:album:2UCyiayMoJOwBilPLQPQvK',\n",
              "   'duration_ms': 247612,\n",
              "   'album_name': 'Nathaniel Rateliff & The Night Sweats'},\n",
              "  {'pos': 75,\n",
              "   'artist_name': 'Sir Sly',\n",
              "   'track_uri': 'spotify:track:17aDyX39gb1iV1ZWvD1ffE',\n",
              "   'artist_uri': 'spotify:artist:3DFoVPonoAAt4EZ1FEI8ue',\n",
              "   'track_name': 'High',\n",
              "   'album_uri': 'spotify:album:5VvCD7gVffRgdPfExxLfF4',\n",
              "   'duration_ms': 231896,\n",
              "   'album_name': \"Don't You Worry, Honey\"},\n",
              "  {'pos': 76,\n",
              "   'artist_name': 'Stanaj',\n",
              "   'track_uri': 'spotify:track:6fJAs9KPgHrN9Fqo0GgWhW',\n",
              "   'artist_uri': 'spotify:artist:3zrUX1hQrUB9aXcOiyQLmN',\n",
              "   'track_name': 'The Way I Love Her',\n",
              "   'album_uri': 'spotify:album:1CBdCd3Wkyhdn1JspaIQ2Y',\n",
              "   'duration_ms': 230213,\n",
              "   'album_name': 'The Way I Love Her'},\n",
              "  {'pos': 77,\n",
              "   'artist_name': 'X Ambassadors',\n",
              "   'track_uri': 'spotify:track:5KrEN8aGZnvS2UU6molPFs',\n",
              "   'artist_uri': 'spotify:artist:3NPpFNZtSTHheNBaWC82rB',\n",
              "   'track_name': 'Ahead Of Myself',\n",
              "   'album_uri': 'spotify:album:2fegGpMdK0zuaBEHGFdYdf',\n",
              "   'duration_ms': 223146,\n",
              "   'album_name': 'Ahead Of Myself'},\n",
              "  {'pos': 78,\n",
              "   'artist_name': 'XXXTENTACION',\n",
              "   'track_uri': 'spotify:track:3GVkPk8mqxz0itaAriG1L7',\n",
              "   'artist_uri': 'spotify:artist:15UsOTVnJzReFVN1VCnxy4',\n",
              "   'track_name': 'Everybody Dies In Their Nightmares',\n",
              "   'album_uri': 'spotify:album:5VdyJkLe3yvOs0l4xXbWp0',\n",
              "   'duration_ms': 95466,\n",
              "   'album_name': '17'},\n",
              "  {'pos': 79,\n",
              "   'artist_name': 'BUNT.',\n",
              "   'track_uri': 'spotify:track:38tGRxFP5NkWbtOWsXbQ0L',\n",
              "   'artist_uri': 'spotify:artist:2CpLIMBoE2ZzyY3ZBCRZ7j',\n",
              "   'track_name': 'Old Guitar',\n",
              "   'album_uri': 'spotify:album:5OMuOXDJwxGMLXvPj9kvqz',\n",
              "   'duration_ms': 208548,\n",
              "   'album_name': 'Old Guitar'},\n",
              "  {'pos': 80,\n",
              "   'artist_name': 'Billie Eilish',\n",
              "   'track_uri': 'spotify:track:7noz6lydFxH30fneHwKMvp',\n",
              "   'artist_uri': 'spotify:artist:6qqNVTkY8uBg9cP3Jd7DAH',\n",
              "   'track_name': 'watch',\n",
              "   'album_uri': 'spotify:album:3iD9gnKk8eu35kRFzSflJ0',\n",
              "   'duration_ms': 177523,\n",
              "   'album_name': 'dont smile at me'},\n",
              "  {'pos': 81,\n",
              "   'artist_name': 'Daya',\n",
              "   'track_uri': 'spotify:track:7y4JznkAv2W3IKw9T1o2VK',\n",
              "   'artist_uri': 'spotify:artist:6Dd3NScHWwnW6obMFbl1BH',\n",
              "   'track_name': 'New',\n",
              "   'album_uri': 'spotify:album:328z7dHptKTWayYVMeoAMW',\n",
              "   'duration_ms': 230879,\n",
              "   'album_name': 'New'},\n",
              "  {'pos': 82,\n",
              "   'artist_name': 'Kygo',\n",
              "   'track_uri': 'spotify:track:4aSfgWmRa9KsISD4Jmx7QB',\n",
              "   'artist_uri': 'spotify:artist:23fqKkggKUBHNkbKtXEls4',\n",
              "   'track_name': 'This Town',\n",
              "   'album_uri': 'spotify:album:2sPYPyDFwgi1jrRTGhoxq2',\n",
              "   'duration_ms': 202280,\n",
              "   'album_name': 'Stargazing - EP'}],\n",
              " 'num_edits': 49,\n",
              " 'duration_ms': 18461552,\n",
              " 'num_artists': 72}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting the data into a useful format**\n",
        "\n",
        "We will now perform the following two steps:\n",
        "\n",
        "1. We create a NetworkX Graph containing all the playlists, tracks, and artists as nodes as well as the names of playlists and tracks, and the node type as node attributes. The album data which was in the original dataset will be dropped.\n",
        "\n",
        "2. We create a Pandas Dataframe which includes each edge as a row including the playlist and song names. The names will be used at a later point in the notebook."
      ],
      "metadata": {
        "id": "t5ReAeNFKhq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: NetworkX Graph**"
      ],
      "metadata": {
        "id": "reqsOO7fK4Ni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following functions are helper functions which turn all required JSON files of Spotify playlists into a NetworkX graph which we will work with later. You don't need to understand how they work, but if you want, feel free to take a look."
      ],
      "metadata": {
        "id": "HhLWfBfXYP_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_playlist_to_graph(G, index, plst_json):\n",
        "    tracks = plst_json['tracks']\n",
        "    plst_array = [(f'plst_{index}', {'name': plst_json['name'], 'type': 'playlist'})]\n",
        "    artist_edges = []\n",
        "\n",
        "    for j, track in enumerate(tracks):\n",
        "        plst_array.append((track['track_uri'], {\n",
        "            'name': track['track_name'],\n",
        "            'type': 'track'\n",
        "        }))\n",
        "        plst_array.append((track['artist_uri'], {'type': 'artist'}))\n",
        "        artist_edges.append((track['artist_uri'], track['track_uri']))\n",
        "\n",
        "    track_uris = [x['track_uri'] for x in tracks]\n",
        "    edge_array = [(f'plst_{index}', x) for x in track_uris]\n",
        "    G.add_nodes_from(plst_array)\n",
        "    G.add_edges_from(edge_array)\n",
        "    G.add_edges_from(artist_edges)"
      ],
      "metadata": {
        "id": "zwrTc39tY6RC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_file_to_graph(G, start_index, file_json):\n",
        "    for i, plst_json in enumerate(file_json['playlists']):\n",
        "        add_playlist_to_graph(G, start_index + i, plst_json)"
      ],
      "metadata": {
        "id": "rlPtxDQiY2AA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_graph_from_files(G, data_path, start_index=None, end_index=None):\n",
        "    assert (start_index is None and end_index is None) or \\\n",
        "        (start_index is not None and end_index is not None), 'Set both or no indices.'\n",
        "    json_names = [f for f in listdir(data_path) if isfile(join(data_path, f)) and '.json' in f]\n",
        "\n",
        "    num_playlists = start_index if start_index is not None else 0\n",
        "    section = json_names if start_index is None else json_names[start_index:end_index]\n",
        "    for file_name in tqdm(section, desc='Files processed: ', unit='files', total=len(section)):\n",
        "        with open(join(data_path, file_name)) as json_file:\n",
        "            data = json.load(json_file)\n",
        "\n",
        "        add_file_to_graph(G, num_playlists, data)\n",
        "        num_playlists += len(data['playlists'])"
      ],
      "metadata": {
        "id": "52xxXIkSXW_m"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now create the NetworkX graph using a subset of the data. We will load the first 100 files containing 100k playlists in total. This might take a while..."
      ],
      "metadata": {
        "id": "QMaCxx-2ZOXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.Graph()\n",
        "generate_graph_from_files(G, DATA_PATH, 0, 50)"
      ],
      "metadata": {
        "id": "4Wf-zcFbZNuo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6081da55439343558e3b7573279d5007",
            "e48bdc257f2e4a5f997b5dc5f295e06d",
            "37853b4c9a3a4eeb88d77e5a38a1fea6",
            "584165521f8f46b686c481d41131cf3a",
            "3f60a1b757c8401db161197a905cff25",
            "ec47ef35ef3f4c51a78b86b676615a9c",
            "3939f645583847018d832004a037a151",
            "abef06aa509c4ef4b6b00ce3aa5432ff",
            "e257eb6d4c9645cc8c1a238945b09e52",
            "780804ff6f9f43fba1106b7e94a5b04d",
            "3ddee00c77aa4b72b15b1680b556a745"
          ]
        },
        "outputId": "27c41332-87ba-489b-cde8-69e2758c6fee"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Files processed:   0%|          | 0/50 [00:00<?, ?files/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6081da55439343558e3b7573279d5007"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save the graph for later retrieval."
      ],
      "metadata": {
        "id": "GD7j15YyZdap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(G, open('plst_track_artist_graph.txt', 'wb'))"
      ],
      "metadata": {
        "id": "nd1U9WneIoPQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "5c787ec0-b59e-4def-b8ab-9dc884d8b92c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pickle' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6a4108b08e11>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'plst_track_artist_graph.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Pandas Dataframe Containing Edge Information (Needed for Optional Notebook Part)**"
      ],
      "metadata": {
        "id": "R7aRXCRjLBxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, the following are helper functions which you don't need to understand. Feel free to have a look at them if you want:"
      ],
      "metadata": {
        "id": "IDpWaydoLm6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_playlist_df(playlist_id, playlist_json):\n",
        "    cols = ['plst_id', 'plst_name', 'track_id', 'track_name']\n",
        "    data_col = []\n",
        "    plst_name = playlist_json['name']\n",
        "\n",
        "    for track in playlist_json['tracks']:\n",
        "        track_id = ''.join(track['track_uri'].split(':')[2:])\n",
        "        data_col.append([f'plst_{playlist_id}', plst_name, track_id, track['track_name']])\n",
        "\n",
        "    plst_df = pd.DataFrame(data=data_col, columns=cols)\n",
        "    return plst_df"
      ],
      "metadata": {
        "id": "jo4kCa0VLme4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_file_df(start_index, file_json):\n",
        "    dfs = []\n",
        "    for i, plst_json in enumerate(file_json['playlists']):\n",
        "        dfs.append(generate_playlist_df(start_index + i, plst_json))\n",
        "\n",
        "    df_sum = pd.concat(dfs)\n",
        "    return df_sum"
      ],
      "metadata": {
        "id": "eVunamQEL7jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_spotify_df(data_path, start_index=None, end_index=None):\n",
        "    assert (start_index is None and end_index is None) or \\\n",
        "        (start_index is not None and end_index is not None), 'Set both or none indices.'\n",
        "    json_names = [f for f in listdir(data_path) if isfile(join(data_path, f)) and '.json' in f]\n",
        "\n",
        "    num_playlists = start_index if start_index is not None else 0\n",
        "    section = json_names if start_index is None else json_names[start_index:end_index]\n",
        "    dfs = []\n",
        "\n",
        "    for file_name in tqdm(section, desc='Files processed: ', unit='files', total=len(section)):\n",
        "        with open(join(data_path, file_name)) as json_file:\n",
        "            data = json.load(json_file)\n",
        "\n",
        "        dfs.append(generate_file_df(num_playlists, data))\n",
        "        num_playlists += len(data['playlists'])\n",
        "\n",
        "    df_total = pd.concat(dfs)\n",
        "    return df_total"
      ],
      "metadata": {
        "id": "QqxbCpM6L8jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now create the dataframe and save it."
      ],
      "metadata": {
        "id": "LPvXA1zXMFI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = generate_spotify_df(DATA_PATH, 0, 50)"
      ],
      "metadata": {
        "id": "-KvouYx5LCZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_pickle('df_50_files.npz')"
      ],
      "metadata": {
        "id": "-8GrLNn1MHlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing the Dataset**"
      ],
      "metadata": {
        "id": "nFC1U4ayUatC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now preprocess the dataset for our analysis."
      ],
      "metadata": {
        "id": "RoUA9W1Du0sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mVkujbYwgdcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loads the entire graph with 100k playlists. This is way too big to use for training, however - the File can be provided upon request."
      ],
      "metadata": {
        "id": "7SSp5Ou5wVkW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vve97TjbesLG"
      },
      "outputs": [],
      "source": [
        "G_orig = pickle.load(open('plst_track_artist_graph.txt', 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fetch the largest connected component**\n",
        "\n",
        "We will work only with one component and leave playlists with songs which don't share connections to other playlists untouched."
      ],
      "metadata": {
        "id": "kPQwWWLgz_G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from networkx.algorithms.components import is_connected\n",
        "is_connected(G_orig)"
      ],
      "metadata": {
        "id": "h27UFHWPaYX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "largest_cc = max(nx.connected_components(G_orig), key=len)\n",
        "G_comp = nx.Graph(G_orig.subgraph(largest_cc))"
      ],
      "metadata": {
        "id": "w2x_CTEXbCqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DSxPEwbenzf"
      },
      "outputs": [],
      "source": [
        "print('Num nodes:', G_comp.number_of_nodes(), '. Num edges:', G_comp.number_of_edges())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Artist Edges**"
      ],
      "metadata": {
        "id": "7I_Kd334n4A9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't need artist nodes for this collaborative filtering problem so we remove them from the graph."
      ],
      "metadata": {
        "id": "Gf0mpnUFwxg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artist_ids = [label for label, attr in G_comp.nodes(data=True) if attr['type'] == 'artist']"
      ],
      "metadata": {
        "id": "lfyVwPtg38N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_comp.remove_nodes_from(artist_ids)"
      ],
      "metadata": {
        "id": "UgpjIHmi4WVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find Central Nodes to Sample Subgraphs**"
      ],
      "metadata": {
        "id": "_qBgwOmBW8I_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to only work on a subgraph of our entire dataset in this Colab because we are resource constrained (25Gb RAM + GPU). Finding central subgraphs in the massive graph we prepared would be too computationally expensive, so we came up with the following idea:\n",
        "\n",
        "1. Using the dataframe created as part of the provided data (see point 2. in \"Loading the dataset\", we counted how many times each track occurs in a playlist (= popularity)\n",
        "\n",
        "2. We ranked playlists by the mean popularity of the tracks they contain.\n",
        "\n",
        "3. We selected a playlist with high popularity songs which by assumption would lie centrally in the Spotify network.\n",
        "\n",
        "4. We sampled a subgraph by creating a 3-hop neighborhood around the highly popular playlist.\n",
        "\n",
        "The popular playlist we chose had the id: *plst_98527*"
      ],
      "metadata": {
        "id": "sheMq9ruxlsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "popular_playlist_start_node = 'plst_9'"
      ],
      "metadata": {
        "id": "0lMTeLXJW6rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "playlists = [label for label, attr in G_comp.nodes(data=True) if attr['type'] == 'playlist']"
      ],
      "metadata": {
        "id": "3k2em7Teb5WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "popular_playlist_start_node in playlists"
      ],
      "metadata": {
        "id": "hJb-ZI21dgSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We sample a 3-hop neighborhood undirected subgraph:"
      ],
      "metadata": {
        "id": "lxj88ZG9y2CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from networkx.generators.ego import ego_graph"
      ],
      "metadata": {
        "id": "bX2M3gfodxoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_ego = ego_graph(G_comp, popular_playlist_start_node, 3, undirected=True)"
      ],
      "metadata": {
        "id": "3sO2YCPtW6wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Num nodes:', G_ego.number_of_nodes(), '. Num edges:', G_ego.number_of_edges())"
      ],
      "metadata": {
        "id": "pCBunyp6d58a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "playlists = [label for label, attr in G_ego.nodes(data=True) if attr['type'] == 'playlist']\n",
        "tracks = [label for label, attr in G_ego.nodes(data=True) if attr['type'] == 'track']\n",
        "len(playlists), len(tracks)"
      ],
      "metadata": {
        "id": "oP29ZDglfegG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the sampled neighborhood has 18'123 playlists and 125'656 edges between playlists and tracks. Again, we can save the data to retrieve it later when needed."
      ],
      "metadata": {
        "id": "OyS5fmRFy_sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(G_ego, open('ego_graph_popular.txt', 'wb'))"
      ],
      "metadata": {
        "id": "LW-SG-OzeW0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_ego = pickle.load(open('ego_graph_popular.txt', 'rb'))"
      ],
      "metadata": {
        "id": "Kv_7_taDigNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualize A Subset Of Our Graph**"
      ],
      "metadata": {
        "id": "6861kom4W6B3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sampled subgraph is still to big to visualize. This is why we sample a subgraph of 7k nodes from our neighborhood graph, find the largest connected component, and visualize this smaller graph for illustration purposes."
      ],
      "metadata": {
        "id": "E41sLH3ezPcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subgraph = np.random.choice([id for (id, attr) in G_ego.nodes(data=True)], size=7000, replace=False)"
      ],
      "metadata": {
        "id": "iO9XoigVXc-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subgraph = G_ego.subgraph(subgraph)"
      ],
      "metadata": {
        "id": "wJzOAat3jXZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "largest_cc = max(nx.connected_components(subgraph), key=len)\n",
        "subgraph = nx.Graph(subgraph.subgraph(largest_cc))"
      ],
      "metadata": {
        "id": "BWTqUjqmlK8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len([label for label, attr in subgraph.nodes(data=True) if attr['type'] == 'playlist'])"
      ],
      "metadata": {
        "id": "AkGr93MyocAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len([label for label, attr in subgraph.nodes(data=True) if attr['type'] == 'track'])"
      ],
      "metadata": {
        "id": "fcQ7sxYopKN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This smaller subgraph has 817 playlists and 1060 tracks. We can again save it in case we want to look at it again."
      ],
      "metadata": {
        "id": "i0HLmz7jze_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(subgraph, open('/content/drive/MyDrive/CS224W/Data/visualized_subgraph.txt', 'wb'))"
      ],
      "metadata": {
        "id": "NpDziLwLpMdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_ego = pickle.load(open('/content/drive/MyDrive/CS224W/Data/visualized_subgraph.txt', 'rb'))"
      ],
      "metadata": {
        "id": "MhhhJvhEH2zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the graph structure:"
      ],
      "metadata": {
        "id": "fqL-mYuxzlzj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xK9g0nz_fUWq"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "color_map = {'playlist': 0, 'track': 1}\n",
        "node_color = [color_map[attr['type']] for (id, attr) in subgraph.nodes(data=True)]\n",
        "nx.draw(subgraph, cmap=plt.get_cmap('coolwarm'), node_color=node_color, node_size=12, width=1, edge_color=(0,0,0,0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optional: Adding Playlist Name Embeddings As Features**"
      ],
      "metadata": {
        "id": "1tdlBQwj0Lgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skip this step if you want to initalize the LightGCN embedding layer randomly from scratch (recommended)."
      ],
      "metadata": {
        "id": "m7BA3k4jz0Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using the popular [Paraphrase MiniLM L6 v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2) model from HuggingFace to create 384-dimensional embeddings of playlist names to initialize the LightGCN embedding layer. The Paraphrase Mini model is very popular because it provides high quality textual embeddings for short sentences or words in only 384 dimensions."
      ],
      "metadata": {
        "id": "AZi37nWdz8mP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize NLP Model"
      ],
      "metadata": {
        "id": "Qf0I8E504DTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will download the pre-trained text embedding model and illustrate some embedding examples."
      ],
      "metadata": {
        "id": "xsA8thZb0ZlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex1 = 'Throwbacks'\n",
        "ex2 = 'Toxic'\n",
        "ex3 = 'Love is great'"
      ],
      "metadata": {
        "id": "bBIn0fGO0KwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "RZit-rM10Sy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Pooling - Take attention mask into account for correct averaging\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
      ],
      "metadata": {
        "id": "LT_a59LF3Z1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentences we want sentence embeddings for\n",
        "sentences = [ex1, ex2, ex3]"
      ],
      "metadata": {
        "id": "I0Ttlcgn3dnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model from HuggingFace Hub\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
        "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "IKCb-4hq0K6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences\n",
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')"
      ],
      "metadata": {
        "id": "1B1r3tvg3pjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute token embeddings\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)"
      ],
      "metadata": {
        "id": "ZJPwi0W53qjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform pooling. In this case, max pooling.\n",
        "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])"
      ],
      "metadata": {
        "id": "w-wgHrfQ3us_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sentence embeddings:\")\n",
        "print(sentence_embeddings.shape)"
      ],
      "metadata": {
        "id": "rS4ufQlq3xPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aren't HuggingFace transformers beautiful! We create 3 384-dimensional embeddings for our example sentences and words."
      ],
      "metadata": {
        "id": "7kePHw780igm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embed Track & Playlist Names"
      ],
      "metadata": {
        "id": "lkk36F344Jli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we write a function to create embeddings for playlist names will generating a dummy feature with all ones for our track names."
      ],
      "metadata": {
        "id": "KDVAY4ZI0qyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from os.path import isfile, join"
      ],
      "metadata": {
        "id": "dZOgbD8x3-Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/CS224W/Data/'"
      ],
      "metadata": {
        "id": "ncJIMNPK4XZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import the dataframe we created to map playlist ids to names."
      ],
      "metadata": {
        "id": "knG08PBP02K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pos = pd.read_pickle(join(DATA_PATH, 'df_100_files.npz'))"
      ],
      "metadata": {
        "id": "6pr_h7t93-Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function creates the embeddings."
      ],
      "metadata": {
        "id": "rERgh6g_09Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_names(G, node_type, batch_size=None, ones=False):\n",
        "    assert node_type == 'playlist' or node_type == 'track', 'Node type must be playlist or track.'\n",
        "    EMBED_SIZE = 384\n",
        "\n",
        "    # Get Names and IDs\n",
        "    old_ids = [label for label, attr in G.nodes(data=True) if attr['type'] == node_type]\n",
        "    ids = old_ids\n",
        "\n",
        "    if ones:\n",
        "        node_features = torch.ones(EMBED_SIZE)\n",
        "        nx.set_node_attributes(G, node_features, 'node_feature')\n",
        "        return\n",
        "\n",
        "    if node_type == 'track':\n",
        "        ids = [''.join(x.split(':')[2:]) for x in old_ids]\n",
        "\n",
        "    short_form = 'plst' if node_type == 'playlist' else node_type\n",
        "    lookup = df_pos[[f'{short_form}_id', f'{short_form}_name']].drop_duplicates().set_index(f'{short_form}_id')\n",
        "    names = lookup.loc[ids][f'{short_form}_name'].tolist()\n",
        "\n",
        "    batch_n = batch_size if batch_size is not None else len(names)\n",
        "    for start_i in tqdm(range(0, len(names), batch_n)):\n",
        "        end_i = start_i + batch_n\n",
        "        name_batch = names[start_i:end_i]\n",
        "\n",
        "        # Embed\n",
        "        encoded_input = tokenizer(name_batch, padding=True, truncation=True, return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            model_output = model(**encoded_input)\n",
        "\n",
        "        embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "        # Assign\n",
        "        features = {id: {'node_feature': embeddings[j]} for j, id in enumerate(old_ids[start_i:end_i])}\n",
        "        nx.set_node_attributes(G, features)"
      ],
      "metadata": {
        "id": "PEtISk3o8Mw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_names(G_ego, 'track')"
      ],
      "metadata": {
        "id": "BVWQxXuMDZGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_names(G_ego, 'playlist')"
      ],
      "metadata": {
        "id": "-nkz3-PG-_gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the embeddings if needed."
      ],
      "metadata": {
        "id": "-hAxla9I1BLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(G_ego, open('/content/drive/MyDrive/CS224W/Data/ego_graph_features.txt', 'wb'))"
      ],
      "metadata": {
        "id": "B7TW-juT0LDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generate A DeepSnap Graph**"
      ],
      "metadata": {
        "id": "WkYDKmxcGp70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to convert our NetworkX object to a DeepSnap graph to profit from the library's link prediction dataset generation capabilities. We also strip unncessary attributes from the graph in order to reduce memory requirements. LightGCN only works on the graph structure itself and does not necessarily require node features, unless we want to initialize the embedding layer with specific features (i.e. our text embedding model)."
      ],
      "metadata": {
        "id": "bwks4VLco0yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nodes = [id for id, attr in G_ego.nodes(data=True)]"
      ],
      "metadata": {
        "id": "2XSpULcnl8IH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = [edge for edge in G_ego.edges()]"
      ],
      "metadata": {
        "id": "5DcvrX38mLc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_ego = nx.Graph()"
      ],
      "metadata": {
        "id": "lYzWWzDEmVbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_ego.add_nodes_from(nodes)\n",
        "G_ego.add_edges_from(edges)"
      ],
      "metadata": {
        "id": "1a5Gvohkmdgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dg = Graph(G_ego)"
      ],
      "metadata": {
        "id": "8fmoS6rqlhW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Generation**"
      ],
      "metadata": {
        "id": "QOyO0VSqjd5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We generate datasets for training, validation, and prediction using DeepSnap. The task we select is link prediction which automatically samples a dataset of positive and negative edges used for training, validation, and prediction. It is important that we use the \"disjoint mode\" for prediction as we want message-flowing edges and prediction edges to be separate from each other."
      ],
      "metadata": {
        "id": "OwPdWl3HpTkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = 'link_pred'\n",
        "dataset = GraphDataset([dg], task=task, edge_train_mode='disjoint')"
      ],
      "metadata": {
        "id": "GXlxeSUU7Tw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The dataset has {dataset.num_edges[0]} edges.')"
      ],
      "metadata": {
        "id": "ySrf53ty7VOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use an 80%, 10%, 10% split between training, validation, and testing sets."
      ],
      "metadata": {
        "id": "JJfOVRHXtkW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1])"
      ],
      "metadata": {
        "id": "HsxNBUdJjvY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_edges = dataset_train[0].edge_label_index.shape[1]\n",
        "num_val_edges = dataset_val[0].edge_label_index.shape[1]\n",
        "num_test_edges = dataset_test[0].edge_label_index.shape[1]\n",
        "\n",
        "print(\"Train set has {} supervision (positive) edges\".format(num_train_edges // 2))\n",
        "print(\"Validation set has {} supervision (positive) edges\".format(num_val_edges // 2))\n",
        "print(\"Test set has {} supervision (positive) edges\".format(num_test_edges // 2))\n",
        "\n",
        "print(\"Train set has {} message passing edges\".format(dataset_train[0].edge_index.shape[1]))\n",
        "print(\"Validation set has {} message passing edges\".format(dataset_val[0].edge_index.shape[1]))\n",
        "print(\"Test set has {} message passing edges\".format(dataset_test[0].edge_index.shape[1]))"
      ],
      "metadata": {
        "id": "7toJFKjw8mTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can execute the next lines to save our datasets to disk for easier retrieval."
      ],
      "metadata": {
        "id": "EhHYuOqZp3ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(dataset_train, open('/content/drive/MyDrive/CS224W/Data/train_homo_big.graph', 'wb'))\n",
        "pickle.dump(dataset_val, open('/content/drive/MyDrive/CS224W/Data/val_homo_big.graph', 'wb'))\n",
        "pickle.dump(dataset_test, open('/content/drive/MyDrive/CS224W/Data/test_homo_big.graph', 'wb'))"
      ],
      "metadata": {
        "id": "hZPo6PyU9IhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and to load the data again:"
      ],
      "metadata": {
        "id": "zCQDs4VPp8qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = pickle.load(open('/content/drive/MyDrive/CS224W/Data/train_homo_big.graph', 'rb'))\n",
        "dataset_val = pickle.load(open('/content/drive/MyDrive/CS224W/Data/val_homo_big.graph', 'rb'))\n",
        "dataset_test = pickle.load(open('/content/drive/MyDrive/CS224W/Data/test_homo_big.graph', 'rb'))"
      ],
      "metadata": {
        "id": "hz2gSFjwvvXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Building LightGCN From Scratch**"
      ],
      "metadata": {
        "id": "013k_GErJNwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the [LightGCN research paper](https://arxiv.org/pdf/2002.02126.pdf) we implemented the LightGCN model completely from scratch using Pytorch, PyTorch Geometric, and DeepSnap.\n",
        "\n",
        "What is unique about LightGCN is that the only trainable parameters are the first layer's embeddings. LightGCN then propagates this information along the graph to optimize the embeddings.\n",
        "\n",
        "We adjusted the original LightGCN model in the following ways:\n",
        "\n",
        "1. The original LightGCN model outputs a rank (scalar) identifying the strength of a connection between a playlist and a track. Since we sampled positive and negative edges, we are not ranking them, but instead want to produce a predicted label. We achieved this by **changing the Bayesian Personalized Ranking (BPR) loss function to a Binary Cross-Entropy (BCE) loss**.\n",
        "\n",
        "2. To make the model more accurate, we **added a Sigmoid layer**, transforming the ranking (a dot-product result) to a binary label.\n",
        "\n",
        "3. We used a **normal mean aggregation instead of a weighted-sum mean aggregation** for our LightGCN convolutional layer because due to the structure of our graph, this would have given to much weight to individual tracks."
      ],
      "metadata": {
        "id": "YvSefpyGnXnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_scatter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Union, Tuple, Optional\n",
        "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType, OptTensor)\n",
        "\n",
        "from torch.nn import Parameter, Linear\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax"
      ],
      "metadata": {
        "id": "CQiImunFJNLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Custom LightGCN Convolutional Layer"
      ],
      "metadata": {
        "id": "15XyNUAe2qW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to build the LightGCN convolutional layer from scratch and define its specific message passing character. We need to do this because the layer is not a pre-defined PyTorch Geometric layer."
      ],
      "metadata": {
        "id": "fz6CNGvx2vGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is the message passing function of our modified LightGCN Convolutional Layer:\n",
        "\n",
        "\\begin{equation}\n",
        "h_v^{(l)} = AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\})\n",
        "\\end{equation}\n",
        "\n",
        "where $AGG(\\cdot)$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\}) = \\frac{1}{|N(v)|} \\sum_{u\\in N(v)} h_u^{(l-1)}\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "qZjwOK1U3Seu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCNConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, normalize = True,\n",
        "                 bias = False, **kwargs):\n",
        "        super(LightGCNConv, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        out = self.propagate(edge_index, x=(x, x))\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "        out = x_j\n",
        "        return out\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "        node_dim = self.node_dim\n",
        "        out = torch_scatter.scatter(inputs, index, dim=node_dim, reduce='mean')\n",
        "        return out"
      ],
      "metadata": {
        "id": "V1ZdSDD4JM-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The LightGCN Model"
      ],
      "metadata": {
        "id": "guzyO2zJ3OHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let us build the LightGCN model which is a bit harder. The LightGCN model needs to be flexible enough for the following:\n",
        "\n",
        "1. Different number of input nodes\n",
        "2. Specify embedding dimensions\n",
        "3. Specify the number of layers\n",
        "4. Pre-initialize the embedding layer with pre-computed tensors"
      ],
      "metadata": {
        "id": "-HIacxdp3Qib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The modified version of our LightGCN model computes the final embeddings as a weighted-sum of each layer's embeddings:\n",
        "\n",
        "\\begin{equation}\n",
        "h_v = \\sum_{l=0}^{L} \\alpha_l h_v^{l}\n",
        "\\end{equation}\n",
        "\n",
        "where $\\alpha_{l}$ can be appropriately chosen for every layer depending on the domain. Note that the initial layer-0 embedding is included in the weighted-sum average as well. In the original paper, $\\alpha_{l}$ is uniformly defined for all layers as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\alpha_{l} = \\frac{1}{K + 1}\n",
        "\\end{equation}\n",
        "\n",
        "and $K$ is the number of layers."
      ],
      "metadata": {
        "id": "epZVXeIF4E6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, because we aren't computing ranking between playlists and tracks but instead a binary score predicting whether the edge exists or not, we change the original LightGCN prediction header (a simple dor product) to the following to obtain our final prediction $\\hat{y}_{vu}$ for a playlist-track pair $vu$:\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{vu} = \\sigma(h_v^T h_u)\n",
        "\\end{equation}\n",
        "\n",
        "Here, $\\sigma(\\cdot)$ is defined to be the sigmoid function."
      ],
      "metadata": {
        "id": "6O9XZqxd5W3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCN(torch.nn.Module):\n",
        "    def __init__(self, train_data, num_layers, emb_size=16, initialize_with_words=False):\n",
        "        super(LightGCN, self).__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        assert (num_layers >= 1), 'Number of layers is not >=1'\n",
        "        for l in range(num_layers):\n",
        "            self.convs.append(LightGCNConv(input_dim, input_dim))\n",
        "\n",
        "        # Initialize using custom embeddings if provided\n",
        "        num_nodes = train_data.node_label_index.size()[0]\n",
        "        self.embeddings = nn.Embedding(num_nodes, emb_size)\n",
        "        if initialize_with_words:\n",
        "            self.embeddings.weight.data.copy_(train_datanode_features)\n",
        "\n",
        "        self.loss_fn = nn.BCELoss()\n",
        "        self.num_layers = num_layers\n",
        "        self.emb_size = emb_size\n",
        "        self.num_modes = num_nodes\n",
        "\n",
        "    def forward(self, data):\n",
        "        edge_index, edge_label_index, node_label_index = data.edge_index, data.edge_label_index, data.node_label_index\n",
        "        layer_embeddings = []\n",
        "\n",
        "        x = self.embeddings(node_label_index)\n",
        "        mean_layer = x\n",
        "\n",
        "        # We take an average of ever layer's node embeddings\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            mean_layer += x\n",
        "\n",
        "        mean_layer /= 4\n",
        "\n",
        "        # Prediction head is simply dot product\n",
        "        nodes_first = torch.index_select(x, 0, edge_label_index[0,:].long())\n",
        "        nodes_second = torch.index_select(x, 0, edge_label_index[1,:].long())\n",
        "\n",
        "        # Since we don't want a rank output, we create a sigmoid of the dot product\n",
        "        out = torch.sum(nodes_first * nodes_second, dim=-1) # FOR RANKING\n",
        "        pred = torch.sigmoid(out)\n",
        "\n",
        "        return torch.flatten(pred)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return self.loss_fn(pred, label)"
      ],
      "metadata": {
        "id": "8ZvqzjXTJMnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define Training & Test Functions**"
      ],
      "metadata": {
        "id": "yf6Mdp9bqrFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to define the hyperparameters and datasets our model should use. We programmed everything in a way so that in easily runs on GPUs in Google Colab or CPU, whatever is preferred."
      ],
      "metadata": {
        "id": "ZV1mkKuP4VDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "z-uawrp7s9q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'device' : 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'num_layers' : 3,\n",
        "    'emb_size' : 32,\n",
        "    'epochs' : 1,\n",
        "    'weight_decay': 1e-5,\n",
        "    'lr': 0.01,\n",
        "    'epochs': 300\n",
        "}\n",
        "\n",
        "datasets = {\n",
        "    'train': dataset_train[0],\n",
        "    'val': dataset_val[0],\n",
        "    'test': dataset_test[0]\n",
        "}\n",
        "\n",
        "input_dim = datasets['train'].num_node_features\n",
        "print(input_dim, args)"
      ],
      "metadata": {
        "id": "w4pETO9wEGMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets['train'].to(args['device'])\n",
        "datasets['val'].to(args['device'])\n",
        "datasets['test'].to(args['device'])"
      ],
      "metadata": {
        "id": "eVZve1eLtDui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, define training and test functions which save the loss and our chosen metrics.\n",
        "\n",
        "For our metrics, we chose to use the area-under-the-curve (ROC-AUC) of whether a given playlist and track belong together or not in a balanced dataset."
      ],
      "metadata": {
        "id": "1QtDmFT44gal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "def train(model, optimizer, args):\n",
        "    val_max = 0\n",
        "    best_model = model\n",
        "\n",
        "    for epoch in range(1, args['epochs'] + 1):\n",
        "        datasets['train'].to(args[\"device\"])\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(datasets['train'])\n",
        "        loss = model.loss(pred, datasets['train'].edge_label.type(pred.dtype))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Loss: {:.5f}, Val Loss: {:.5f}'\n",
        "        score_train, train_loss = test(model, 'train', args)\n",
        "        score_val, val_loss = test(model, 'val', args)\n",
        "        score_test, test_loss = test(model, 'test', args)\n",
        "\n",
        "        losses.append((train_loss, val_loss))\n",
        "\n",
        "        print(log.format(epoch, score_train, score_val, score_test, train_loss, val_loss))\n",
        "        if val_max < score_val:\n",
        "            val_max = score_val\n",
        "            best_model = copy.deepcopy(model)\n",
        "\n",
        "    return best_model\n",
        "\n",
        "def test(model, mode, args):\n",
        "    model.eval()\n",
        "    score = 0\n",
        "    loss_score = 0\n",
        "\n",
        "    data = datasets[mode]\n",
        "    data.to(args[\"device\"])\n",
        "\n",
        "    pred = model(data)\n",
        "    loss = model.loss(pred, data.edge_label.type(pred.dtype))\n",
        "    score += roc_auc_score(data.edge_label.flatten().cpu().numpy(), pred.flatten().data.cpu().numpy())\n",
        "    loss_score += loss.item()\n",
        "\n",
        "    return score, loss_score"
      ],
      "metadata": {
        "id": "0Otb4smZUrY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Start Training**"
      ],
      "metadata": {
        "id": "M7YQQdisELjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know - we can't wait either! Go ahead and run the model using your parameters of choice."
      ],
      "metadata": {
        "id": "oxlKu6-D4z7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LightGCN(datasets['train'], args['num_layers'], emb_size=args['emb_size']).to(args['device'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "\n",
        "best_model = train(model, optimizer, args)\n",
        "log = \"Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Val Loss: {:.5f}, Test Loss: {:.5f}\"\n",
        "best_train_roc, train_loss = test(best_model, 'train', args)\n",
        "best_val_roc, val_loss = test(best_model, 'val', args)\n",
        "best_test_roc, test_loss = test(best_model, 'test', args)\n",
        "print(log.format(best_train_roc, best_val_roc, best_test_roc, train_loss, val_loss, test_loss))"
      ],
      "metadata": {
        "id": "1fGUoRxdUMe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks absolutely beautiful. As you can see, our best model gets low validation and test losses and high train, validation, and test ROC-AUCs. Also, our model doesn't seem to overfit."
      ],
      "metadata": {
        "id": "df6N2bhU5Gpr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now save the best model for later retrieval:"
      ],
      "metadata": {
        "id": "sHuUfx7d5Wp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(best_model, open('/content/drive/MyDrive/CS224W/Data/best_model_big.model', 'wb'))"
      ],
      "metadata": {
        "id": "5Xn6IngmQiwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation**"
      ],
      "metadata": {
        "id": "k06RKzUwvq9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's always nice to plot how our model did during training. Let's program a function which quickly visualizes our training and validation loss curves."
      ],
      "metadata": {
        "id": "8uVqVALu5Z5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "7QMxNOs4wASC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(losses, title):\n",
        "    train_loss, val_loss = zip(*losses)\n",
        "    steps = list(range(1, len(train_loss) + 1))\n",
        "\n",
        "    min_val_loss = np.round(np.min(val_loss), 3)\n",
        "\n",
        "    plt.figure(figsize=(16, 6))\n",
        "    plt.plot(steps, train_loss, '-r', label='Training Loss')\n",
        "    plt.plot(steps, val_loss, '-b', label='Validation Loss')\n",
        "    plt.hlines(min_val_loss, 1, 300, colors='k', linestyles='dotted', label='Min Validation Loss: {}'.format(min_val_loss))\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.ylim((0.58, 0.71))\n",
        "    plt.title(title)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(title)\n",
        "\n",
        "    return plt"
      ],
      "metadata": {
        "id": "V42C9SEJVy6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curve(losses, 'LightGCN on Spotify Popular Playlist 3-Hop Neighborhood')"
      ],
      "metadata": {
        "id": "EnAzzBWJ5k7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Final Remarks**"
      ],
      "metadata": {
        "id": "QW0yVV2L5_ON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congrats! You created a graph ML model which does neural collaborative filtering on Spotify playlists and tracks to predict whether a given track belongs to a playlist or not.\n",
        "\n",
        "You could use your model to test a number of tracks against your own playlists just on the basis of what similar people to you like."
      ],
      "metadata": {
        "id": "q4mrvA9y5z-r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PNNMh1LSi1GW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6081da55439343558e3b7573279d5007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e48bdc257f2e4a5f997b5dc5f295e06d",
              "IPY_MODEL_37853b4c9a3a4eeb88d77e5a38a1fea6",
              "IPY_MODEL_584165521f8f46b686c481d41131cf3a"
            ],
            "layout": "IPY_MODEL_3f60a1b757c8401db161197a905cff25"
          }
        },
        "e48bdc257f2e4a5f997b5dc5f295e06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec47ef35ef3f4c51a78b86b676615a9c",
            "placeholder": "​",
            "style": "IPY_MODEL_3939f645583847018d832004a037a151",
            "value": "Files processed: 100%"
          }
        },
        "37853b4c9a3a4eeb88d77e5a38a1fea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abef06aa509c4ef4b6b00ce3aa5432ff",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e257eb6d4c9645cc8c1a238945b09e52",
            "value": 50
          }
        },
        "584165521f8f46b686c481d41131cf3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_780804ff6f9f43fba1106b7e94a5b04d",
            "placeholder": "​",
            "style": "IPY_MODEL_3ddee00c77aa4b72b15b1680b556a745",
            "value": " 50/50 [01:45&lt;00:00,  1.95s/files]"
          }
        },
        "3f60a1b757c8401db161197a905cff25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec47ef35ef3f4c51a78b86b676615a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3939f645583847018d832004a037a151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abef06aa509c4ef4b6b00ce3aa5432ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e257eb6d4c9645cc8c1a238945b09e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "780804ff6f9f43fba1106b7e94a5b04d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ddee00c77aa4b72b15b1680b556a745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}